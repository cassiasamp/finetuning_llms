{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7f6058-d0d1-44af-b43a-cb4b06df03d8",
   "metadata": {},
   "source": [
    "# Prompting Capabilities \n",
    "\n",
    "- Note, you can try any of these prompts outside of this classroom, and without coding, by going to the chat interface [Le Chat](https://chat.mistral.ai/chat).\n",
    "  - You can sign up with a free account.\n",
    "  - Signing up for an account is **not** required to complete this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daa37d97-10e4-425d-b852-15bd043662b9",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistralai\n",
      "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
      "Collecting httpx<0.26.0,>=0.25.2\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m381.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3.0.0,>=2.5.2\n",
      "  Using cached pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.10\n",
      "  Downloading orjson-3.10.3-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (253 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.3/253.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /Users/csamp/mambaforge/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.4)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: certifi in /Users/csamp/mambaforge/lib/python3.9/site-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2023.5.7)\n",
      "Collecting anyio\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting pydantic-core==2.18.2\n",
      "  Using cached pydantic_core-2.18.2-cp39-cp39-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/csamp/mambaforge/lib/python3.9/site-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.7.1)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting exceptiongroup>=1.0.2\n",
      "  Downloading exceptiongroup-1.2.1-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: sniffio, pydantic-core, orjson, h11, exceptiongroup, annotated-types, pydantic, httpcore, anyio, httpx, mistralai\n",
      "Successfully installed annotated-types-0.6.0 anyio-4.3.0 exceptiongroup-1.2.1 h11-0.14.0 httpcore-1.0.5 httpx-0.25.2 mistralai-0.1.8 orjson-3.10.3 pydantic-2.7.1 pydantic-core-2.18.2 sniffio-1.3.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install mistralai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b3ac64-1295-4a0e-90ab-51c338c945f7",
   "metadata": {},
   "source": [
    "- Notice that it's \"mistralai\", and not \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff393a84-303a-48ae-97fe-3551f524f733",
   "metadata": {},
   "source": [
    "### Load API key and helper function\n",
    "- Note: You can view or download the helper.py file by clicking on the \"Jupyter\" logo to access the file directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f6a5640-203a-4e7a-bc4c-4bfe78da4099",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_mistral_api_key\n\u001b[1;32m      2\u001b[0m load_mistral_api_key()\n",
      "File \u001b[0;32m~/Documents/llms_courses/mistral_ai/helper.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv     \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmistralai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MistralClient\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmistralai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_completion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatMessage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from helper import load_mistral_api_key\n",
    "load_mistral_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e030d9c2-1ecb-4bf0-864d-9f96b41bd016",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dotenv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mistral\n\u001b[1;32m      2\u001b[0m mistral(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello, what can you do?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/llms_courses/mistral_ai/helper.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdotenv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dotenv, find_dotenv     \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmistralai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MistralClient\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmistralai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_completion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatMessage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dotenv'"
     ]
    }
   ],
   "source": [
    "from helper import mistral\n",
    "mistral(\"hello, what can you do?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98a29ef-4764-40b7-aed8-0e5d0502f985",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e9d1c-ca45-4d19-882c-07e077ea19ad",
   "metadata": {
    "height": 642
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    You are a bank customer service bot. \n",
    "    Your task is to assess customer intent and categorize customer \n",
    "    inquiry after <<<>>> into one of the following predefined categories:\n",
    "    \n",
    "    card arrival\n",
    "    change pin\n",
    "    exchange rate\n",
    "    country support \n",
    "    cancel transfer\n",
    "    charge dispute\n",
    "    \n",
    "    If the text doesn't fit into any of the above categories, \n",
    "    classify it as:\n",
    "    customer service\n",
    "    \n",
    "    You will only respond with the predefined category. \n",
    "    Do not provide explanations or notes. \n",
    "    \n",
    "    ###\n",
    "    Here are some examples:\n",
    "    \n",
    "    Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card as expected. Could you please provide information about the tracking process for my card, or confirm if there are any indicators to identify if the card has been lost during delivery?\n",
    "    Category: card arrival\n",
    "    Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for foreign transactions.\n",
    "    Category: exchange rate \n",
    "    Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany, and would appreciate any information regarding compatibility and functionality in these regions.\n",
    "    Category: country support\n",
    "    Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the issue. \n",
    "    Category: customer service\n",
    "    ###\n",
    "    \n",
    "    <<<\n",
    "    Inquiry: {inquiry}\n",
    "    >>>\n",
    "    Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d367f-cc2c-4857-abd5-d1f6a545ebc0",
   "metadata": {},
   "source": [
    "#### Ask Mistral to check the spelling and grammar of your prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a2ecd-e542-4863-96dc-29786c003799",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "response = mistral(f\"Please correct the spelling and grammar of \\\n",
    "this prompt and return a text that is the same prompt,\\\n",
    "with the spelling and grammar fixed: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476f0db5-ba51-43ca-a4c4-dc2b072291ba",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bbf68-a0bc-4e8a-bb6b-8ae20f3f2e2d",
   "metadata": {},
   "source": [
    "#### Try out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4625fdc0-c6ef-4dcf-bbc0-d250a0ed277c",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "mistral(\n",
    "    response.format(\n",
    "        inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252e995-f3fc-4e62-abdb-3e367df55cbe",
   "metadata": {},
   "source": [
    "## Information Extraction with JSON Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6741a613-5b1b-4fb1-9843-1c5737f36cd5",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "medical_notes = \"\"\"\n",
    "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
    "of increased thirst, frequent urination, fatigue, and unexplained\n",
    "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
    "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
    "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
    "with meals. It was noted during the consultation that the patient is\n",
    "a current smoker. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2bd7a-48c9-4c0b-8a4a-049a43045805",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Extract information from the following medical notes:\n",
    "{medical_notes}\n",
    "\n",
    "Return json format with the following JSON schema: \n",
    "\n",
    "{{\n",
    "        \"age\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"gender\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"male\", \"female\", \"other\"]\n",
    "        }},\n",
    "        \"diagnosis\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
    "        }},\n",
    "        \"weight\": {{\n",
    "            \"type\": \"integer\"\n",
    "        }},\n",
    "        \"smoking\": {{\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"yes\", \"no\"]\n",
    "        }}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a0b58-aae5-45e2-8496-714b884f16b6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "response = mistral(prompt, is_json=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a9cb95-bb08-4929-b16c-eb19877f3c01",
   "metadata": {},
   "source": [
    "## Personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf048b4-3e33-4753-af97-25b73c51ee6a",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Dear mortgage lender, \n",
    "\n",
    "What's your 30-year fixed-rate APR, how is it compared to the 15-year \n",
    "fixed rate?\n",
    "\n",
    "Regards,\n",
    "Anna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36de7c1e-60c2-4f35-a51a-115b12d65bb6",
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "You are a mortgage lender customer service bot, and your task is to \n",
    "create personalized email responses to address customer questions.\n",
    "Answer the customer's inquiry using the provided facts below. Ensure \n",
    "that your response is clear, concise, and directly addresses the \n",
    "customer's question. Address the customer in a friendly and \n",
    "professional manner. Sign the email with \"Lender Customer Support.\"   \n",
    "      \n",
    "# Facts\n",
    "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
    "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
    "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
    "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
    "7-year ARM: interest rate 7.011%, APR 7.660%\n",
    "5-year ARM: interest rate 6.880%, APR 7.754%\n",
    "3-year ARM: interest rate 6.125%, APR 7.204%\n",
    "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
    "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
    "\n",
    "# Email\n",
    "{email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf50774-0f91-4e0e-86c9-1525f6045ebb",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfaad2c-411e-4221-80f0-7acd21ba398c",
   "metadata": {},
   "source": [
    "## Summarization\n",
    "\n",
    "- We'll use this [article](https://www.deeplearning.ai/the-batch/mistral-enhances-ai-landscape-in-europe-with-microsoft-partnership-and-new-language-models) from The Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbab492-1d18-4832-86a9-2fba645e0e52",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "newsletter = \"\"\"\n",
    "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft. \n",
    "\n",
    "What’s new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
    "\n",
    "Model specs: The new models’ parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context. \n",
    "\n",
    "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic’s Claude 2, Google’s Gemini Pro, and Meta’s Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
    "Both models are fluent in French, German, Spanish, and Italian. They’re trained for function calling and JSON-format output.\n",
    "Microsoft’s investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon’s investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
    "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
    "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France’s representatives in the European Commission argued on Mistral’s behalf to loosen the European Union’s AI Act oversight on powerful AI models. \n",
    "\n",
    "Yes, but: Mistral AI’s partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft’s agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron’s Renaissance party criticized the deal’s potential to give a U.S. company access to European users’ data. However, other French lawmakers support the relationship.\n",
    "\n",
    "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that’s tailored to Europe’s unique regulatory environment.\n",
    "\n",
    "We’re thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaede63d-7392-4f1c-8a87-507ee31fe246",
   "metadata": {
    "height": 472
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter. \n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question. \n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format. \n",
    "\n",
    "# Newsletter: \n",
    "{newsletter}\n",
    "\n",
    "# Instructions: \n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes \n",
    "presented in the newsletter.\n",
    "\n",
    "## Interesting Questions: \n",
    "Generate three distinct and thought-provoking questions that can be \n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem \n",
    "- After \"A: \", provide a detailed explanation of the problem addressed \n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions, \n",
    "create a comprehensive report in Markdown format. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5505b0a5-411b-4804-aaef-ccecfa3d07be",
   "metadata": {
    "height": 47,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6590c2-2558-45be-84cb-b1b99dbc3776",
   "metadata": {},
   "source": [
    "#### Try it out for yourself\n",
    "- Feel free to copy-paste text from another article in The Batch, or any other blog or news article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter2 = \"\"\"\n",
    "April 2024, what a month! My birthday, a new book release, spring is finally here, and four major open LLM releases: Mixtral, Meta AI's Llama 3, Microsoft's Phi-3, and Apple's OpenELM.\n",
    "\n",
    "This article reviews and discusses all four major transformer-based LLM model releases that have been happening in the last few weeks, followed by new research on reinforcement learning with human feedback methods for instruction finetuning using PPO and DPO algorithms.\n",
    "\n",
    "1. How Good are Mixtral, Llama 3, and Phi-3?\n",
    "\n",
    "2. OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework\n",
    "\n",
    "3. Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study\n",
    "\n",
    "4. Other Interesting Research Papers In April\n",
    "\n",
    "1. Mixtral, Llama 3, and Phi-3: What's New?\n",
    "First, let's start with the most prominent topic: the new major LLM releases this month. This section will briefly cover Mixtral, Llama 3, and Phi-3, which have been accompanied by short blog posts or short technical papers. The next section will cover Apple's OpenELM in a bit more detail, which thankfully comes with a research paper that shares lots of interesting details.\n",
    "\n",
    "1.1 Mixtral 8x22B: Larger models are better!\n",
    "Mixtral 8x22B is the latest mixture-of-experts (MoE) model by Mistral AI, which has been released under a permissive Apache 2.0 open-source license.\n",
    "\n",
    "Similar to the Mixtral 8x7B released in January 2024, the key idea behind this model is to replace each feed-forward module in a transformer architecture with 8 expert layers. It's going to be a relatively long article, so I am skipping the MoE explanations, but if you are interested, the Mixtral 8x7B section in an article I shared a few months ago is a bit more detailed:\n",
    "\n",
    "The perhaps most interesting plot from the Mixtral blog post, which compares Mixtral 8x22B to several LLMs on two axes: modeling performance on the popular Measuring Massive Multitask Language Understanding (MMLU) benchmark and active parameters (related to computational resource requirements).\n",
    "\n",
    "1.2 Llama 3: Larger data is better!\n",
    "Meta AI's first Llama model release in February 2023 was a big breakthrough for openly available LLM and was a pivotal moment for open(-source) LLMs. So, naturally, everyone was excited about the Llama 2 release last year. Now, the Llama 3 models, which Meta AI has started to roll out, are similarly exciting.\n",
    "\n",
    "While Meta is still training some of their largest models (e.g., the 400B variant), they released models in the familiar 8B and 70B size ranges. And they are good! Below, I added the MMLU scores from the official Llama 3 blog article to the Mixtral plot I shared earlier.\n",
    "\n",
    "Overall, the Llama 3 architecture is almost identical to Llama 2. The main differences are the increased vocabulary size and the fact that Llama 3 also uses grouped-query attention for the smaller-sized model. If you are looking for a grouped-query attention explainer, I've written about it here:\n",
    "\n",
    "\n",
    "Below are the configuration files used for implementing Llama 2 and Llama 3 in LitGPT, which help show the main differences at a glance.\n",
    "\n",
    "Training data size\n",
    "\n",
    "The main contributor to the substantially better performance compared to Llama 2 is the much larger dataset. Llama 3 was trained on 15 trillion tokens, as opposed to \"only\" 2 trillion for Llama 2.\n",
    "\n",
    "This is a very interesting finding because, as the Llama 3 blog post notes, according to the Chinchilla scaling laws, the optimal amount of training data for an 8 billion parameter model is much smaller, approximately 200 billion tokens. Moreover, the authors of Llama 3 observed that both the 8 billion and 70 billion parameter models demonstrated log-linear improvements even at the 15 trillion scale. This suggests that we (that is, researchers in general) could further enhance the model with more training data beyond 15 trillion tokens.\n",
    "\n",
    "Instruction finetuning and alignment\n",
    "\n",
    "For instruction finetuning and alignment, researchers usually choose between using reinforcement learning with human feedback (RLHF) via proximal policy optimization (PPO) or the reward-model-free direct preference optimization (DPO). Interestingly, the Llama 3 researchers did not favor one over the other; they used both! (More on PPO and DPO in a later section.)\n",
    "\n",
    "The Llama 3 blog post stated that a Llama 3 research paper would follow in the coming month, and I am looking forward to the additional details that will hopefully be shared in this article.\n",
    "\n",
    "1.3 Phi-3: Higher-quality data is better!\n",
    "Just one week after the big Llama 2 release, Microsoft shared their new Phi-3 LLM. According to the benchmarks in the technical report, even the smallest Phi-3 model outperforms the Llama 3 8B model despite being less than half its size.\n",
    "\n",
    "\n",
    "Notably, Phi-3, which is based on the Llama architecture, has been trained on 5x fewer tokens than Llama 3 (3.3 trillion instead of 15 trillion). Phi-3 even uses the same tokenizer with a vocabulary size of 32,064 as Llama 2, which is much smaller than the Llama 3 vocabulary size.\n",
    "\n",
    "Also, Phi-3-mini has \"only\" 3.8 billion parameters, which is less than half the size of Llama 3 8B.\n",
    "\n",
    "So, What is the secret sauce? According to the technical report, it's dataset quality over quantity: \"heavily filtered web data and synthetic data\".\n",
    "\n",
    "The paper didn't go into too much detail regarding the data curation, but it largely follows the recipe used for previous Phi models. I wrote more about Phi models a few months ago here:\n",
    "\n",
    "As of this writing, people are still unsure whether Phi-3 is really as good as promised. For instance, many people I talked to noted that Phi-3 is much worse than Llama 3 for non-benchmark tasks.\n",
    "1.4 Conclusion\n",
    "Based on the three major releases described above, this has been an exceptional month for openly available LLMs. And I haven't even talked about my favorite model, OpenELM, which is discussed in the next section.\n",
    "\n",
    "Which model should we use in practice? I think all three models above are attractive for different reasons. Mixtral has a lower active-parameter count than Llama 3 70B but still maintains a pretty good performance level. Phi-3 3.8B may be very appealing for mobile devices; according to the authors, a quantized version of it can run on an iPhone 14. And Llama 3 8B might be the most interesting all-rounder for fine-tuning since it can be comfortably fine-tuned on a single GPU when using LoRA.\n",
    "\n",
    "2. OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework\n",
    "OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework is the latest LLM model suite and paper shared by researchers at Apple, aiming to provide small LLMs for deployment on mobile devices.\n",
    "\n",
    "Similar to the OLMo, it's refreshing to see an LLM paper that shares details discussing the architecture, training methods, and training data. \n",
    "\n",
    "\n",
    "Let's start with the most interesting tidbits:\n",
    "\n",
    "OpenELM comes in 4 relatively small and convenient sizes: 270M, 450M, 1.1B, and 3B\n",
    "\n",
    "For each size, there's also an instruct-version available trained with rejection sampling and direct preference optimization\n",
    "\n",
    "OpenELM performs slightly better than OLMo even though it's trained on 2x fewer tokens\n",
    "\n",
    "The main architecture tweak is a layer-wise scaling strategy\n",
    "\n",
    "2.1 Architecture details\n",
    "Besides the layer-wise scaling strategy (more details later), the overall architecture settings and hyperparameter configuration are relatively similar to other LLMs like OLMo and Llama, as summarized in the figure below.\n",
    "2.2 Training dataset\n",
    "Sharing details is different from explaining them as research papers aimed to do when I was a student. For instance, they sampled a relatively small subset of 1.8T tokens from various public datasets (RefinedWeb, RedPajama, The PILE, and Dolma). This subset was 2x smaller than Dolma, which was used for training OLMo. But what was the rationale for this subsampling, and what were the sampling criteria?\n",
    "\n",
    "One of the authors kindly followed up with me on that saying \"Regarding dataset: We did not have any rationale behind dataset sampling, except we wanted to use public datasets of about 2T tokens (following LLama2).\"\n",
    "2.3 Layer-wise scaling\n",
    "The layer-wise scaling strategy (adopted from the DeLighT: Deep and Light-weight Transformer paper) is very interesting. Essentially, the researchers gradually widen the layers from the early to the later transformer blocks. In particular, keeping the head size constant, the researchers increase the number of heads in the attention module. They also scale the hidden dimension of the feed-forward module, as illustrated in the figure below.\n",
    "I wish there was an ablation study training an LLM with and without the layer-wise scaling strategy on the same dataset. But those experiments are expensive, and I can understand why it wasn't done.\n",
    "\n",
    "However, we can find ablation studies in the DeLighT: Deep and Light-weight Transformer paper that first introduced the layer-wise scaling on a smaller dataset based on the original encoder-decoder architecture, as shown below.\n",
    "\n",
    "\n",
    "2.4 LoRA vs DoRA\n",
    "An interesting bonus I didn't expect was that the researchers compared LoRA and DoRA (which I discussed a few weeks ago) for parameter-efficient finetuning! It turns out that there wasn't a noticeable difference between the two methods, though.\n",
    "\n",
    "2.5 Conclusion\n",
    "While the paper doesn't answer any research questions, it's a great, transparent write-up of the LLM implementation details. The layer-wise scaling strategy might be something that we could see more often in LLMs from now on. Also, the paper is only one part of the release. For further details, Apple also shared the OpenELM code on GitHub.\n",
    "\n",
    "Anyways, great work, and big kudos to the researchers (and Apple) for sharing!\n",
    "\n",
    "3. Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study\n",
    "Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study finally answers one of the key questions I've been raising in previous months. \n",
    "\n",
    "Let's start with a brief overview before diving into the results: Both PPO (proximal policy optimization) and DPO (direct preference optimization) are popular methods for aligning LLMs via reinforcement learning with human feedback (RLHF). \n",
    "\n",
    "RLHF is a key component of LLM development, and it's used to align LLMs with human preferences, for example, to improve the safety and helpfulness of LLM-generated responses.\n",
    "\n",
    "For a more detailed explanation and comparison, also see the Evaluating Reward Modeling for Language Modeling section in my Tips for LLM Pretraining and Evaluating Reward Models article that I shared last month.\n",
    "\n",
    "3.1 What are RLHF-PPO and DPO?\n",
    "RLHF-PPO, the original LLM alignment method, has been the backbone of OpenAI's InstructGPT and the LLMs deployed in ChatGPT. However, the landscape has shifted in recent months with the emergence of DPO-finetuned LLMs, which have made a significant impact on public leaderboards. This surge in popularity can be attributed to DPO's reward-free alternative, which is notably easier to use: Unlike PPO, DPO doesn't require training a separate reward model but uses a classification-like objective to update the LLM directly.\n",
    "\n",
    "Today, most LLMs on top of public leaderboards have been trained with DPO rather than PPO. Unfortunately, though, there have not been any direct head-to-head comparisons where the same model was trained with either PPO or DPO using the same dataset until this new paper came along. \n",
    "\n",
    "3.2 PPO is generally better than DPO\n",
    "Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study is a well-written paper with lots of experiments and results, but the main takeaways are that PPO is generally better than DPO, and DPO suffers more heavily from out-of-distribution data.\n",
    "\n",
    "Here, out-of-distribution data means that the LLM has been previously trained on instruction data (using supervised finetuning) that is different from the preference data for DPO. For example, an LLM has been trained on the general Alpaca dataset before being DPO-finetuned on a different dataset with preference labels. (One way to improve DPO on out-of-distribution data is to add a supervised instruction-finetuning round on the preference dataset before following up with DPO finetuning).\n",
    "\n",
    "The main findings are summarized in the figure below.\n",
    "\n",
    "\n",
    "In addition to the main results above, the paper includes several additional experiments and ablation studies that I recommend checking out if you are interested in this topic. \n",
    "\n",
    "3.3 Best practices\n",
    "Furthermore, interesting takeaways from this paper include best-practice recommendations when using DPO and PPO.\n",
    "\n",
    "For instance, if you use DPO, make sure to perform supervised finetuning on the preference data first. Also, iterative DPO, which involves labeling additional data with an existing reward model, is better than DPO on the existing preference data.\n",
    "\n",
    "If you use PPO, the key success factors are large batch sizes, advantage normalization, and parameter updates via an exponential moving average.\n",
    "\n",
    "3.4 Conclusion\n",
    "Based on this paper's results, PPO seems superior to DPO if used correctly. However, given that DPO is more straightforward to use and implement, I expect DPO to remain a popular go-to method. \n",
    "\n",
    "A good practical recommendation may be to use PPO if you have ground truth reward labels (so you don't have to pretrain your own reward model) or if you can download an in-domain reward model. Otherwise, use DPO for simplicity.\n",
    "\n",
    "Also, based on what we know from the LLama 3 blog post, we don't have to decide whether to use PPO or DPO, but we can use both! For instance, the recipe behind Llama 3 has been the following pipeline: Pretraining → supervised finetuning → rejection sampling → PPO → DPO. (I am hoping the Llama 3 developers will share a paper with more details soon!)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0b13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter. \n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question. \n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format. \n",
    "\n",
    "# Newsletter: \n",
    "{newsletter2}\n",
    "\n",
    "# Instructions: \n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes \n",
    "presented in the newsletter.\n",
    "\n",
    "## Interesting Questions: \n",
    "Generate three distinct and thought-provoking questions that can be \n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem \n",
    "- After \"A: \", provide a detailed explanation of the problem addressed \n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions, \n",
    "create a comprehensive report in Markdown format. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ee6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "response2 = mistral(prompt2)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed88147-8d43-4207-b45b-06543371f913",
   "metadata": {},
   "source": [
    "## The Mistral Python client\n",
    "- Below is the helper function that you imported from helper.py and used earlier in this notebook.\n",
    "- For more details, check out the [Mistral AI API documentation](https://docs.mistral.ai/api/)\n",
    "- To get your own Mistral AI API key to use on your own, outside of this classroom, you can create an account and go to the [console](https://console.mistral.ai/) to subscribe and create an API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ef7a7f-ebd6-49c3-8f91-5f5d284edf17",
   "metadata": {
    "height": 353
   },
   "outputs": [],
   "source": [
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage   \n",
    "\n",
    "def mistral(user_message, \n",
    "            model=\"mistral-small-latest\",\n",
    "            is_json=False):\n",
    "    client = MistralClient(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages,\n",
    "            response_format={\"type\": \"json_object\"})\n",
    "    else:\n",
    "        chat_response = client.chat(\n",
    "            model=model, \n",
    "            messages=messages)\n",
    "        \n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd279d2-d4cd-4465-9d65-8143a16c4bca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
